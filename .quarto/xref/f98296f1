{"entries":[],"headings":["chapter-9-alignment-and-rlhf","what-well-learn-today","the-alignment-problem-smart-aligned","what-is-ai-alignment","the-simple-definition","the-classic-example-the-paperclip-maximizer","why-language-models-need-alignment","the-pre-training-misalignment","real-examples-of-misalignment","the-three-hs-helpful-harmless-honest","helpful-actually-assisting-users","harmless-avoiding-negative-consequences","honest-truthfulness-and-transparency","rlhf-teaching-models-human-preferences","the-three-stage-rlhf-process","the-big-picture","stage-1-supervised-fine-tuning-sft","the-foundation-phase","sft-data-examples","stage-2-reward-model-training","the-preference-learning-phase","data-collection-process","example-ranking-task","the-reward-model-architecture","stage-3-reinforcement-learning-with-ppo","the-optimization-phase","ppo-proximal-policy-optimization","the-training-loop","rlhf-challenges-and-solutions","challenge-1-reward-hacking","challenge-2-scalability","challenge-3-distributional-shift","constitutional-ai-teaching-principles","the-motivation","beyond-human-feedback","the-constitutional-approach","the-constitutional-ai-process","phase-1-critique-and-revision","phase-2-reinforcement-learning","example-constitutional-ai-in-action","scenario-harmful-request","scenario-complex-ethical-question","advanced-alignment-techniques","debate-and-recursive-reward-modeling","ai-debate","recursive-reward-modeling","interpretability-and-transparency","understanding-model-reasoning","mechanistic-interpretability","robustness-and-safety","adversarial-testing-red-teaming","safety-evaluations","current-challenges-and-open-problems","the-alignment-tax","performance-vs.-safety-trade-offs","scalable-oversight","the-supervision-problem","value-learning-and-specification","whose-values","the-orthogonality-thesis","practical-implementation-guide","building-an-rlhf-pipeline","step-1-data-collection","step-2-model-training","step-3-rl-training","evaluation-and-monitoring","human-evaluation","automated-safety-checks","real-world-case-studies","case-study-1-chatgpt-development","openais-rlhf-journey","case-study-2-claudes-constitutional-ai","anthropics-approach","case-study-3-research-lab-safety-testing","academic-rlhf-implementation","key-takeaways","fun-exercises","exercise-1-preference-ranking","exercise-2-constitutional-principles","exercise-3-red-team-challenge","whats-next","final-thought"]}