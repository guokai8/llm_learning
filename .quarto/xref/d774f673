{"entries":[],"headings":["chapter-8-fine-tuning-techniques","what-well-learn-today","what-is-fine-tuning-the-specialization-stage","the-two-stage-learning-paradigm","analogy-becoming-a-specialist-doctor","for-language-models","why-fine-tuning-is-powerful","the-transfer-learning-magic","efficiency-benefits","supervised-fine-tuning-sft-the-traditional-approach","how-supervised-fine-tuning-works","the-basic-process","example-training-a-qa-model","creating-high-quality-training-data","data-collection-strategies","data-quality-best-practices","training-process-and-hyperparameters","learning-rate-strategy","training-schedule","preventing-catastrophic-forgetting","parameter-efficient-fine-tuning-the-smart-way","the-problem-with-full-fine-tuning","resource-requirements","the-efficiency-insight","lora-low-rank-adaptation","the-core-idea","mathematical-intuition","lora-in-practice","lora-hyperparameters","qlora-quantized-lora","the-memory-optimization","when-to-use-qlora","other-parameter-efficient-methods","prefix-tuning","adapter-layers","iaÂ³-infused-adapter-by-inhibiting-and-amplifying","comparing-parameter-efficient-methods","domain-adaptation-teaching-specialized-knowledge","understanding-domain-adaptation","the-domain-gap-problem","adaptation-strategies","case-study-adapting-to-medical-domain","phase-1-domain-pre-training","phase-2-task-fine-tuning","evaluation-results","domain-adaptation-best-practices","data-collection-strategies-1","balancing-general-vs.-domain-knowledge","instruction-tuning-teaching-models-to-follow-directions","what-is-instruction-tuning","the-goal","why-its-powerful","training-data-for-instruction-tuning","dataset-creation","instruction-diversity","popular-instruction-datasets","training-process","the-instruction-following-format","multi-task-training","alignment-and-rlhf-making-models-helpful-and-safe","the-alignment-problem","what-is-alignment","why-standard-training-isnt-enough","reinforcement-learning-from-human-feedback-rlhf","the-rlhf-process-3-stages","the-reward-model","constitutional-ai-teaching-models-principles","the-concept","self-critique-and-revision","when-to-fine-tune-vs.-when-to-prompt","the-decision-framework","fine-tuning-is-better-when","prompting-is-better-when","cost-benefit-analysis","fine-tuning-costs","prompting-costs","hybrid-approaches","prompt-engineering-fine-tuning","in-context-learning-with-specialized-models","real-world-case-studies","case-study-1-customer-service-chatbot","the-challenge","the-solution","case-study-2-code-generation-assistant","the-challenge-1","the-solution-1","case-study-3-scientific-research-assistant","the-challenge-2","the-solution-2","key-takeaways","fun-exercises","exercise-1-method-selection","exercise-2-lora-design","exercise-3-data-creation","whats-next","final-thought"]}