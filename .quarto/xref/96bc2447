{"entries":[],"headings":["chapter-13-optimization-and-inference","what-well-learn-today","the-inference-challenge-from-lab-to-production","the-reality-check","training-vs.-inference-different-worlds","the-production-requirements","the-computational-bottlenecks","memory-bandwidth-the-hidden-villain","autoregressive-generation-sequential-dependency","the-kv-cache-challenge","model-compression-smaller-models-same-intelligence","quantization-reducing-precision","from-32-bit-to-16-bit-and-beyond","why-quantization-works","quantization-strategies","pruning-removing-unnecessary-connections","structured-vs.-unstructured-pruning","magnitude-based-pruning","attention-head-pruning","knowledge-distillation-teaching-smaller-models","the-teacher-student-framework","distillation-example","inference-optimization-techniques","batching-strategies","static-batching","dynamic-batching","continuous-batching","attention-optimization","flashattention-memory-efficient-attention","multi-query-attention-mqa","grouped-query-attention-gqa","speculative-decoding","the-core-idea","example-execution","serving-frameworks-and-infrastructure","popular-serving-frameworks","vllm-high-throughput-inference","tensorrt-llm-nvidias-optimized-engine","text-generation-inference-tgi-hugging-faces-solution","load-balancing-and-scaling","horizontal-scaling-strategies","auto-scaling-patterns","hardware-acceleration","gpu-optimization","memory-hierarchy-understanding","kernel-fusion","specialized-hardware","tpus-tensor-processing-units","custom-ai-chips","cpu-inference-optimization","when-to-use-cpu","cost-optimization-strategies","understanding-inference-costs","cost-components","cost-per-token-analysis","optimization-strategies","model-selection-trade-offs","caching-strategies","request-routing","performance-monitoring-and-debugging","key-metrics-to-track","latency-metrics","throughput-metrics","quality-metrics","profiling-and-optimization","gpu-profiling-tools","common-performance-issues","real-world-optimization-case-studies","case-study-1-chatgpt-optimization","scaling-challenges","case-study-2-code-generation-optimization","github-copilots-approach","case-study-3-mobile-deployment","on-device-llm-optimization","key-takeaways","fun-exercises","exercise-1-optimization-strategy-design","exercise-2-quantization-analysis","exercise-3-cost-optimization","whats-next","final-thought"]}